// Assumption - we should not get more than 1e4 data points (around 7 days in 1 min granularity)
// So, O(n^2) algorithms should be acceptable (assuming the constant factor is within 10 basic operations).
var TimeSeriesImpl = /** @class */ (function () {
    function TimeSeriesImpl(intervalInMs) {
        this._chunks = [];
        this._intervalInMs = intervalInMs;
    }
    TimeSeriesImpl.isChunkAffected = function (start, end, startChunk, endChunk) {
        if (start <= startChunk && startChunk <= end) {
            return true;
        }
        else if (start <= endChunk && endChunk <= end) {
            return true;
        }
        else if (startChunk <= start && end <= endChunk) {
            return true;
        }
        else if (start <= startChunk && endChunk <= end) {
            return true;
        }
        return false;
    };
    // [start, end] should be within one chunk. If they're not it means we have some data missing and need to issue a query.
    TimeSeriesImpl.prototype.Get = function (start, end) {
        if (!this._chunks) {
            return null;
        }
        for (var i = 0; i < this._chunks.length; ++i) {
            if (this._chunks[i].start <= start && end <= this._chunks[i].end) {
                var chunk = this._chunks[i];
                // O(n) is okay here: n < 1e4
                var from = 0;
                for (; from < chunk.data.length; ++from) {
                    if (start <= chunk.data[from][0]) {
                        break;
                    }
                }
                // O(n) is okay here: n < 1e4
                var to = chunk.data.length - 1;
                for (; to >= 0; --to) {
                    if (chunk.data[to][0] <= end) {
                        break;
                    }
                }
                if (from > to) {
                    return []; // no data found
                }
                var clonedData = this._chunks[i].data.slice(from, to + 1);
                return clonedData;
            }
        }
        return null;
    };
    // Merge new data with existing chunks. This might lead to merging of adjacent chunks as well.
    TimeSeriesImpl.prototype.Store = function (start, end, data) {
        // Remove affected chunks from a list
        var affectedChunks = this.exciseAffectedChunks(start, end);
        // Merge affected chunks together
        var chunk = {
            start: start,
            end: end,
            data: []
        };
        for (var i = 0; i < affectedChunks.length; ++i) {
            chunk.start = new Date(Math.min(chunk.start.getTime(), affectedChunks[i].start.getTime()));
            chunk.end = new Date(Math.max(chunk.end.getTime(), affectedChunks[i].end.getTime()));
            (_a = chunk.data).push.apply(_a, affectedChunks[i].data);
        }
        // Now merge with new data
        // Assumptions:
        // data.length < 1e3 (18 hours 1 min granularity)
        // total length < 1e4 (7 days)
        // O(n^2) should be okay here
        for (var i = 0; i < data.length; ++i) {
            var j = 0;
            for (; j < chunk.data.length; ++j) {
                if (data[i][0] < chunk.data[j][0]) {
                    chunk.data.splice(j, 0, data[i]);
                    break;
                }
                if (data[i][0] > chunk.data[j][0]) {
                    continue;
                }
                // Override data (Kusto might take time to process data)
                chunk.data[j][1] = data[i][1];
                break;
            }
            if (j === chunk.data.length) {
                chunk.data.push(data[i]);
            }
        }
        // Insert chunk back
        var index = 0;
        for (; index < this._chunks.length; ++index) {
            if (chunk.start > this._chunks[index].start) {
                continue;
            }
            break;
        }
        this._chunks.splice(index, 0, chunk);
        var _a;
    };
    TimeSeriesImpl.prototype.exciseAffectedChunks = function (start, end) {
        // We need to merge chunks if they are adjacent, subtracting and adding one interval respectively
        var adjustedStart = new Date(start.getTime() - this._intervalInMs);
        var adjustedEnd = new Date(end.getTime() + this._intervalInMs);
        // Finding affected chunks
        var from = this._chunks.length;
        var to = -1;
        for (var i = 0; i < this._chunks.length; ++i) {
            if (TimeSeriesImpl.isChunkAffected(adjustedStart, adjustedEnd, this._chunks[i].start, this._chunks[i].end)) {
                from = Math.min(from, i);
                to = Math.max(to, i);
            }
        }
        // No intersections found
        if (from > to) {
            return [];
        }
        // Removed affected chunks from the array and return them
        var affectedChunks = this._chunks.splice(from, to - from + 1);
        return affectedChunks;
    };
    return TimeSeriesImpl;
}());
export { TimeSeriesImpl };
var TimeSeriesCache = /** @class */ (function () {
    function TimeSeriesCache() {
        this._cache = {};
    }
    TimeSeriesCache.prototype.Get = function (key, start, end) {
        var val = this._cache[key];
        if (val) {
            return val.Get(start, end);
        }
        return null;
    };
    TimeSeriesCache.prototype.Store = function (key, intervalInMs, start, end, data) {
        var val = this._cache[key];
        if (!val) {
            this._cache[key] = new TimeSeriesImpl(intervalInMs);
            val = this._cache[key];
        }
        val.Store(start, end, data);
    };
    TimeSeriesCache.prototype.Clear = function () {
        this._cache = {};
    };
    return TimeSeriesCache;
}());
export { TimeSeriesCache };
//# sourceMappingURL=TimeSeriesCache.js.map